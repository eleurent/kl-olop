\documentclass{beamer}


\usepackage{etex}
\usepackage{pgffor}
\usepackage[utf8]{inputenc}
%\reserveinserts{28}

\usepackage[backend=biber, citestyle=authoryear, maxcitenames=2, maxbibnames=20]{biblatex}
\bibliography{../biblio.bib}

\usepackage{amsmath,amssymb,amsthm,dsfont}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{color}
\usepackage{esint}
\usepackage{stmaryrd}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage[squaren]{SIunits}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{diagbox}
\usepackage{pdfpages}
\usepackage{dsfont}
\usepackage{xcolor}
\usepackage{soul}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{algorithmic}

\usepackage{hyperref}
\usepackage{multimedia}
\usepackage{array}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{eso-pic}
\usepackage{monster2e}
\usepackage{tikz}
\usepackage{svg}
\usepackage{layout}
\usepackage{xcolor}
\usepackage{fancybox}
\usepackage{setspace}
\usepackage{bbding}
\usepackage{calc}
\usepackage{multicol}
\usepackage[absolute,showboxes,overlay]{textpos}
\usetikzlibrary{calc,fadings,mindmap,trees,arrows,calc,tikzmark,shapes}
\usepackage[flushleft]{threeparttable}


\TPshowboxesfalse
\textblockorigin{0mm}{0mm}
\newcommand{\mathcolorbox}[2]{\colorbox{#1}{$\displaystyle #2$}}

% Icons
\newcommand{\vcenteredinclude}[2]{\begingroup
\setbox0=\hbox{\includesvg[scale=#2]{#1}}%
\parbox{\wd0}{\box0}\endgroup}


% Change margins for slides
\newenvironment{changemargin}[2]{% 
	\begin{list}{}{% 
			\setlength{\topsep}{0pt}% 
			\setlength{\leftmargin}{#1}% 
			\setlength{\rightmargin}{#2}% 
			\setlength{\listparindent}{\parindent}% 
			\setlength{\itemindent}{\parindent}% 
			\setlength{\parsep}{\parskip}% 
		}% 
		\item[]}{\end{list}} 


% Input
\input{style}
\input{../mathdef}
\newtheorem{proposition}{Proposition}
\newtheorem{assumption}{Assumption}
\newtheorem{remark}{Remark}
\newtheorem{property}{Property}

% Style

\TPshowboxesfalse
\textblockorigin{0mm}{0mm}

\setbeamertemplate{footline}{% 
  \hfill% 
  \usebeamercolor[fg]{page number in head/foot}% 
  \usebeamerfont{page number in head/foot}% 
  \insertframenumber%
  %\,/\,\inserttotalframenumber
  \kern1em\vskip2pt% 
}
\beamertemplatenavigationsymbolsempty
\setbeamertemplate{navigation symbols}{}
%\setbeamertemplate{blocks}[rounded]
%\setbeamercolor{block title}{bg=bleu2,fg=white}%bg=background, fg= foreground
%\setbeamercolor{block body}{bg=lightgray}%bg=background, fg= foreground
\renewcommand{\sfdefault}{lmss}
\sffamily
\setbeamersize{text margin left=1cm,text margin right=1cm}


\author[shortname]{
Edouard Leurent \inst{1}, \inst{2} \and 
Odalric-Ambrym Maillard\inst{1}}
\institute[shortinst]{\inst{1} Inria SequeL.\and %
                      \inst{2} Renault Group.}

\title[]{Practical Open-Loop Optimistic Planning}
\date{}
\begin{document}
	
\setbeamertemplate{background canvas}[vertical shading][top=bleu2,middle=bleu2,bottom=bleu1]
\setbeamertemplate{footline}{\hspace{5em} \textcolor{white} {\null \hfill
		\scriptsize WÃ¼rzburg, September 2019}\hspace{2em}\null \vspace*{3pt}}
	
\begin{frame}
\begin{textblock*}{40mm}[0,0](10mm,0mm)
	\includegraphics[width=3.4cm]{inria/inria_tab}
\end{textblock*}
\begin{textblock*}{40mm}[0,0](14mm,3mm)
	\includegraphics[width=2.6cm]{inria/renault_group}
\end{textblock*}

\begin{textblock*}{11.8cm}(4mm,40mm)
	\vspace{.3cm}
	\textcolor{white} {
		\Large \textbf{\hspace{0.5em}Practical Open-Loop Optimistic Planning}\\
		{\small %
			\vspace{1cm}
			\hspace{1.5em}\large\textbf{Edouard Leurent$^{1,2}$, Odalric-Ambrym Maillard$^1$}\\
			\hspace{2.5em}${}^1$ SequeL, Inria Lille -- Nord Europe\\
			\hspace{2.5em}${}^2$ Renault Group\\
	}}
\end{textblock*}

\begin{textblock*}{40mm}[0,0](10mm,76mm)
	\begin{picture}(5,80)
	\put(0,20){\includegraphics[width=3.8cm,height=1.5cm]{inria/logobasVT}}
	\put(13,35){
		\footnotesize \textcolor{bleu2}{ECML PKDD 2019}
	}
	\end{picture}
\end{textblock*}

\vspace*{-4pt}
\end{frame}

\setbeamertemplate{background canvas}[vertical shading][top=blanc, middle=blanc,bottom=blanc]
\setbeamercolor{footlinecolor}{fg=blanc,bg=bleu2}
\setbeamertemplate{footline}
{
\begin{beamercolorbox}[wd=1\paperwidth,ht=15.5pt]{footlinecolor}
		\hspace{3mm}
		\includegraphics[width=14mm]{inria/logobastrans}
		\hspace{.4cm}
		\raisebox{3.2ex}
		{\scriptsize Practical Open-Loop Optimistic Planning}\hfill
		\raisebox{3.2ex}
		{ECML PKDD 2019 - \insertframenumber/\inserttotalframenumber \hspace{5mm}
			\null }
\end{beamercolorbox}
}

\begin{frame}{Motivation | Sequential Decision Making}
\begin{center}
    \includegraphics[trim=0 275 0 25,clip, width=0.75\linewidth]{img/diagram1.pdf}
\end{center}

\begin{block}{Markov Decision Processes}
\pause
\begin{enumerate}
    \item Observe state $s\in S$;\pause
    \item Pick a \hlb{discrete} action $a\in A$;\pause
    \item Transition to a next state $s'\sim \hler{\probability{s'|s,a}}$;\pause
    \item Receive a \hlb{bounded} reward $r\in[0, 1]$ drawn from $\hler{\probability{r|s, a}}$.\pause
\end{enumerate}
\begin{center}
    Objective: maximise \hlg{V = $\expectedvalue \left[\sum_{t=0}^\infty \gamma^t r_t \right]$}
\end{center}
\end{block}
\end{frame}


\begin{frame}{Motivation | Example}
\begin{block}{The \texttt{highway-env} environment \href{https://github.com/eleurent/highway-env}{\vcenteredinclude{img/github}{0.04}}}
\begin{center}
    \href{https://github.com/eleurent/highway-env}{\includegraphics[width=\linewidth]{img/highway-env}}
\end{center}
We want to handle stochasticity.
\end{block}
\end{frame}

\begin{frame}{Motivation | How to solve MDPs?}
\begin{exampleblock}{Online \emph{Planning}}
\begin{itemize}
    \item we have access to a \hlg{generative model}: 
    \begin{itemize}
        \item[\incarrow] yields samples of $s', r \sim \probability{s',r|s,a}$ when queried
    \end{itemize}
\end{itemize}
\begin{center}
    \includegraphics<1>[trim=0 25 0 50,clip, width=0.7\linewidth]{img/diagram2.pdf}
    \includegraphics<2>[trim=0 25 0 50,clip, width=0.7\linewidth]{img/diagram3.pdf}
    \includegraphics<3>[trim=0 25 0 50,clip, width=0.7\linewidth]{img/diagram4.pdf}
    \includegraphics<4>[trim=0 25 0 50,clip, width=0.7\linewidth]{img/diagram5.pdf}
    \includegraphics<5>[trim=0 25 0 50,clip, width=0.7\linewidth]{img/diagram6.pdf}
    \includegraphics<6>[trim=0 25 0 50,clip, width=0.7\linewidth]{img/diagram7.pdf}
\end{center}
\end{exampleblock}
\end{frame}

\begin{frame}{Motivation | How to solve MDPs?}
\begin{exampleblock}{Online \emph{Planning}}
\begin{itemize}
    \item \hlr{fixed budget}: the model can only be queried $n$ times
\end{itemize}
\begin{center}
Objective: minimize $\expectedvalue \underbrace{\hler{V^* - V(n)}}_{\text{Simple Regret }r_n}$
\end{center}
\begin{flushright}
An \hlb{exploration-exploitation} problem.
\end{flushright}
\end{exampleblock}
\end{frame}


\begin{frame}{Optimistic Planning}
    % \begin{alertblock}{Previously: Combinatorial Search}
    % \begin{itemize}
    %     \item Branch pruning and heuristic utility functions
    % \end{itemize}
    % \end{alertblock}
    
    \begin{exampleblock}{Optimism in the Face of Uncertainty}
    Given a set of options $a\in A$ with uncertain outcomes, try the one with the \hlg{highest possible outcome}.\pause
    
    \begin{itemize}
        \item Either you performed well;\pause
        \item or you learned something.\pause
    \end{itemize}
    \end{exampleblock}
    
    \begin{block}{Instances}
    \begin{itemize}
        \item Monte-carlo tree search (\texttt{MCTS}) [\cite{Coulom2006}]: \texttt{CrazyStone}
        \item Reframed in the bandit setting as \texttt{UCT} [\cite{Kocsis2006}], still very popular (e.g. \texttt{Alpha Go}).
        \item Proved \hlg{asymptotic consistency}, but \hlr{no regret bound}.
    \end{itemize}
    \end{block}
\end{frame}


\begin{frame}{Analysis of \texttt{UCT}}
    It was analysed in [\cite{Coquelin2007}]
    \begin{center}
    \includegraphics[width=0.8\textwidth]{img/uct_fail}
    \end{center}
    The sample complexity of is lower-bounded by \hlr{$O(\exp(\exp(D)))$}.
\end{frame}

\begin{frame}{Failing cases of \texttt{UCT}}
    Not just a theoretical counter-example.
    \begin{center}
    \includegraphics<1>[width=0.8\textwidth]{img/uct_trap}
    %\includegraphics<2>[width=0.8\textwidth]{img/uct_trap_2}
    \\ \bigskip
    \includesvg[width=0.5\textwidth]{img/uct_fail_hw}
    \end{center}
\end{frame}

\begin{frame}{Can we get better guarantees?}
    \begin{block}{\OPD: Optimistic Planning for Deterministic systems}
    \begin{itemize}
        \item Introduced by [\cite{Hren2008}]
        \item Another \hlg{optimistic} algorithm
        \item Only for \hlr{deterministic} MDPs
    \end{itemize}
    \end{block}
    \begin{theorem}[\OPD sample complexity]
    \begin{equation*}
    \expectedvalue r_n = 
      \cO\left(n^{-\frac{\log 1/\gamma}{\log \kappa}}\right), \text{if}\ \kappa > 1 
    \end{equation*}
    \end{theorem}
    \pause
\begin{block}{\OLOP: Open-Loop Optimistic Planning}
    \begin{itemize}
        \item Introduced by [\cite{Bubeck2010}]
        \item Extends \OPD to the \hlg{stochastic} setting
        \item Only considers \hlr{open-loop} policies, i.e. sequences of actions
    \end{itemize}
    \end{block}
\end{frame}

% \begin{frame}{A Benchmark of Planning Algorithms}
%     \small
%     \begin{threeparttable}
%     \centering
%     \begin{tabular}{cccc}
%     \toprule
%         Algorithm & Complexity & Does it run? & Does it work?\\
%         \midrule
%         \texttt{MCTS} & ? & \hlg{YES} & ?\\
%         \texttt{SparseSampling}\tnote{1} & $(1/\epsilon)^{\log 1/\epsilon}$ & \hlg{YES} & \hlr{NO} \\
%         \texttt{UCT} & $\exp(\exp(D))$ & \hlg{YES} & \hly{KIND OF} \\
%         \texttt{OPD}\tnote{2} & $n^{-\frac{\log1/\gamma}{\log \kappa}}$ & \hlg{YES} & \hlg{YES} \\
%         \OLOP & $n^{-\min(\frac{1}{2}, \frac{\log1/\gamma}{\log \kappa})}$ & \hly{KIND OF} & \hlr{NO} \\
%         \texttt{ST0P}\tnote{1} & $(1/\epsilon)^{2+\frac{\log \kappa'}{\log1/\gamma}+o(1)}$ & \hlr{NO} & ? (\hlr{NO})\\
%         \texttt{TrailBlazer}\tnote{1} & $(1/\epsilon)^{\frac{\log N\kappa}{\log1/\gamma}}(\log\frac{1}{\delta\epsilon})^\alpha$ & \hlg{YES} & \hlr{NO}\\
%         \texttt{PlatYPOOs}\tnote{2} & $\leq$ \OLOP & \hlg{YES} & \hlg{YES}\\
%         \bottomrule
%     \end{tabular}
    
%     \begin{tablenotes}
%     \item[1] In the PAC framework. 
%     \item[2] With deterministic dynamics
%     \end{tablenotes}
%     \end{threeparttable}
% \end{frame}


\begin{frame}{The idea behind \OLOP}
\begin{block}{A direct application of Optimism in the Face of Uncertainty}
\begin{enumerate}
    \item We want \[\max_a V(a)\] \pause
    \item Form {upper confidence-bounds} of sequence values: \[ V(a) \leq U_a \quad \text{w.h.p}\] \pause
    \item Sample the sequence with highest UCB: \[\argmax_a U_a\]
\end{enumerate}
\end{block}
\end{frame}

\begin{frame}{The idea behind \OLOP}
\begin{center}
\includesvg[width=0.8\textwidth]{img/olop-explain}
\end{center}
\end{frame}

\begin{frame}{The idea behind \OLOP}
\begin{center}
\includesvg[width=0.8\textwidth]{img/olop-explain-2}
\end{center}
\end{frame}


\begin{frame}{Under the hood}
\begin{block}{Upper-bounding the value of sequences}

\end{block}
\begin{align*}
  \only<1>{V(a) =  \overbrace{\sum_{t=1}^h \gamma^t \mu_{a_{1:t}}}^{\text{follow the sequence}} + \overbrace{\sum_{t\geq h+1} \gamma^t \mu_{a^*_{1:t}}}^{\text{act optimally}} \\}
  \only<2>{V(a) =  \overbrace{\sum_{t=1}^h \gamma^t \underbrace{\mu_{a_{1:t}}}_{\leq U^\mu}}^{\text{follow the sequence}} + \overbrace{\sum_{t\geq h+1} \gamma^t \underbrace{\mu_{a^*_{1:t}}}_{\leq 1}}^{\text{act optimally}} \\}
\end{align*}

\end{frame}

\begin{frame}{Under the hood}
    \begin{block}{\OLOP main tool: the Chernoff-Hoeffding deviation inequality}
        \begin{equation*}
             \underbrace{U^{\mu}_a(m)}_{\text{Upper bound}} \eqdef \underbrace{\hat{\mu}_a(m)}_{\text{Empirical mean}} + \underbrace{\sqrt{\frac{2 \log M}{T_a(m)}}}_{\text{Confidence interval}}
        \end{equation*}
    \end{block}
    \pause
    
    \begin{block}{\OPD: upper-bound all the future rewards by 1}
    \begin{equation*}
    \label{eq:Ua}
        U_a(m) \eqdef \sum_{t=1}^h \underbrace{\gamma^t U^{\mu}_{a_{1:t}}(m)}_{\text{Past rewards}} + \underbrace{\frac{\gamma^{h+1}}{1-\gamma}}_{\text{Future rewards}}
    \end{equation*}
    \end{block}
    \pause
    
    \begin{block}{\emph{Bounds sharpening}}
    \begin{equation*}
    \label{eq:Ba}
        B_a(m) \eqdef \inf_{1 \leq t \leq L} U_{a_{1:t}}(m)
    \end{equation*}
    \end{block}
\end{frame}


\begin{frame}{\OLOP guarantees}
\begin{theorem}[\OLOP Sample complexity]
\label{thm:regret}
\OLOP satisfies:
\begin{equation*}
    \expectedvalue r_n = \begin{cases}
      \tilde{\cO}\left(n^{-\frac{\log 1/\gamma}{\log \kappa'}}\right), & \text{if}\ \gamma\sqrt{\kappa'} > 1 \\
      \tilde{\cO}\left(n^{-\frac{1}{2}}\right), & \text{if}\ \gamma\sqrt{\kappa'} \leq 1
    \end{cases}
\end{equation*}
\end{theorem}
\begin{center}
    \emph{"Remarkably, in the case $\kappa \gamma^2 > 1$, we obtain the same rate for the simple regret as Hren and Munos (2008). Thus, in this case, we can say that planning in stochastic environments is not harder than planning in deterministic environments".}
\end{center}
\end{frame}


\begin{frame}{Does it work?}
\begin{center}
    \includesvg[width=0.7\textwidth]{img/hw_return_olop_fail} \\
    Our objective: \hlb{understand} and \hlg{bridge} this gap.
\end{center}
\begin{flushright}
Make \OLOP \emph{practical}.
\end{flushright}
\end{frame}

\begin{frame}{What's wrong with \OLOP?}
    \begin{alertblock}{Explanation: inconsistency}
    \begin{itemize}
        \item Unintended behaviour happens when $\hler{U^{\mu}_a(m) > 1}, \forall a$.
        \begin{equation*}
             U^{\mu}_a(m) = \underbrace{\hat{\mu}_a(m)}_{\in [0,1]} + \underbrace{\sqrt{\frac{2 \log M}{T_a(m)}}}_{> 0}
        \end{equation*}
        \pause
        \item Then the sequence $(U_{a_{1:t}}(m))_t$ is increasing
        \begin{align*}
        U_{a_{1:1}}(m) &=   \textcolor{gray}{\gamma U^{\mu}_{a_{1}}(m)} + \gamma^2 1 &+ \textcolor{gray}{\gamma^3 1 + \dots} \\
        U_{a_{1:2}}(m) &=  \textcolor{gray}{\gamma U^{\mu}_{a_{1}}(m)} + \gamma^2 \underbrace{U^{\mu}_{a_{2}}}_{>1} &+ \textcolor{gray}{\gamma^3 1 + \dots}
        \end{align*}
        \pause
        \item Then \hlr{$B_a(m) = U_{a_{1:1}}(m)$}
    \end{itemize}
    \end{alertblock}
    
\end{frame}

\begin{frame}{What's wrong with \OLOP?}
\begin{block}{What we were promised}
\begin{center}
\includesvg[width=0.8\textwidth]{img/olop-explain-2}
\end{center}
\end{block}
\end{frame}

\begin{frame}{What's wrong with \OLOP?}
\begin{alertblock}{What we actually get}
\begin{center}
\includesvg[width=0.8\textwidth]{img/olop-explain-3}
\end{center}
\end{alertblock}
\begin{flushright}
\OLOP behaves as \hlr{uniform planning}!
\end{flushright}
\end{frame}

% \begin{frame}{What's wrong with \OLOP?}
%     \begin{block}{How long does it last?}
%     \begin{itemize}
%         \item As long as $\hler{U^{\mu}_a(m) > 1}, \forall a$.
%     \begin{equation*}
%          U^{\mu}_a(m) = \underbrace{\hat{\mu}_a(m)}_{\in [0,1]} + \underbrace{\sqrt{\frac{2 \log M}{T_a(m)}}}_{> 0}
%     \end{equation*}
%     \pause
%     \item[\incarrow] $U^{\mu}_a(m)$ decreases as $\cO\left(1/\sqrt{T_a(m)}\right)$
%     \pause
%     \item[\incarrow] The issue lasts longer where $\underbrace{\hat{\mu}_a(m) \simeq 1}_{\text{near-optimal regions}}$
%     \end{itemize}
%     \end{block}
% \end{frame}

\begin{frame}{Our contribution: Kullback-Leibler \OLOP}
    We summon the upper-confidence bound from \texttt{kl-UCB} [\cite{Cappe2013}]:
    \begin{equation*}
        U^{\mu}_a(m) \eqdef \max \left\{q\in I: T_a(m) d(\hat{\mu}_a(m), q) \leq f(m) \right\}
    \end{equation*}
    \pause
    \begin{center}
    \begin{tabular}{ccc}
    \toprule
        Algorithm & \OLOP & \KLOLOP \\
        \midrule
        Interval $I$ & $\mathbb{R}$ & [0, 1] \\
        Divergence $d$ & $d_{\texttt{QUAD}}$ & $d_{\texttt{BER}}$ \\
        $f(m)$ & $4 \log M$ & $2\log M + 2 \log\log M$\\
        \bottomrule
    \end{tabular}
    \end{center}
    
    \begin{align*}
    d_{\texttt{QUAD}}(p,q) &\eqdef 2(p-q)^2\\
    d_{\texttt{BER}}(p, q) &\eqdef p \log \frac{p}{q} + (1-p)\log\frac{1-p}{1-q}
    \end{align*}
\end{frame}

\begin{frame}{Our contribution: Kullback-Leibler \OLOP}
\begin{center}
\vspace{-2em}
    \includegraphics[width=0.6\textwidth]{../img/ukl}
\end{center}
\vspace{-1em}
\pause
And now,
\begin{itemize}
    \item \hlg{$U^{\mu}_a(m) \in I = [0, 1], \forall a$}. \pause 
    \item The sequence $(U_{a_{1:t}}(m))_t$ is \hlg{non-increasing} \pause
    \item $B_a(m) = U_a(m)$, the \emph{bound sharpening} step is \hlb{superfluous}.
\end{itemize}
\end{frame}

\begin{frame}{Sample complexity}

\begin{theorem}[Sample complexity]
\label{thm:regret}
\KLOLOP enjoys the same regret bounds as \OLOP. More precisely, \KLOLOP satisfies:
\begin{equation*}
    \expectedvalue r_n = \begin{cases}
      \tilde{\cO}\left(n^{-\frac{\log 1/\gamma}{\log \kappa'}}\right), & \text{if}\ \gamma\sqrt{\kappa'} > 1 \\
      \tilde{\cO}\left(n^{-\frac{1}{2}}\right), & \text{if}\ \gamma\sqrt{\kappa'} \leq 1
    \end{cases}
\end{equation*}
\end{theorem}
\end{frame}

\begin{frame}{Time complexity}
\begin{block}{Original \KLOLOP}
\emph{Compute $B_a(m-1)$ from \eqref{eq:Ba} \hlr{for all $a\in A^L$}}
\end{block}
\begin{block}{Lazy \KLOLOP}
\centering
\includesvg[width=0.6\textwidth]{../img/tree.svg}
\end{block}

\begin{property}[Time and memory complexity]
\begin{equation*}
    \frac{C(\texttt{Lazy KL-OLOP})}{C(\KLOLOP)} = \frac{\hleg{nK}}{\hler{K^{L}}}
\end{equation*}
\end{property}
\end{frame}

\begin{frame}{Experiments | Expanded Trees}
    \includesvg[width=\textwidth]{../img/tree_OPD}
\end{frame}

\begin{frame}{Experiments | Expanded Trees}
    \includesvg[width=\textwidth]{../img/tree_OLOP}
\end{frame}

\begin{frame}{Experiments | Expanded Trees}
    \includesvg[width=\textwidth]{../img/tree_KL-OLOP}
\end{frame}

\begin{frame}{Experiments | Highway}
    \includesvg[width=\textwidth]{../img/hw_return}
\end{frame}
\begin{frame}{Experiments | Gridworld}
    \includesvg[width=\textwidth]{../img/gw_return}
\end{frame}
\begin{frame}{Experiments | Stochastic Gridworld}
    \includesvg[width=\textwidth]{../img/gw_stoch_return}
\end{frame}

\begin{frame}
        \frametitle{References}
        \printbibliography
\end{frame}

\begin{frame}{}
\begin{center}
    \Huge Thank You.
\end{center}
\end{frame}

% \begin{frame}{Takeway message}
% \begin{columns}
% \begin{column}{0.66\linewidth}
% \begin{block}{Beware of the gap between theory and practice}
% \small
%     \begin{itemize}
%         \item<1-> Asymptotic bounds are good indicators...
%         \item<2-> but they do not always tell the whole story.
%         \item<3-> Time is finite, and constants matter.
%     \end{itemize}
% \end{block}
% \end{column}
% \begin{column}{0.33\linewidth}
% \includegraphics[width=\linewidth]{img/mind-the-gap}
% \end{column}
% \end{columns}
% \pause
% \pause
% \pause
% \begin{center}
%     \Huge Thank You.
% \end{center}
% \end{frame}

\end{document}

