\documentclass{beamer}


\usepackage{etex}
\usepackage{pgffor}
\usepackage[utf8]{inputenc}
%\reserveinserts{28}

\usepackage[backend=biber, citestyle=authoryear, maxcitenames=2, maxbibnames=20]{biblatex}
\bibliography{../biblio.bib}

\usepackage{amsmath,amssymb,amsthm,dsfont}
\usepackage{amsfonts}
\usepackage{mathtools}
\usepackage{color}
\usepackage{esint}
\usepackage{stmaryrd}
\usepackage{tabularx}
\usepackage{multirow}
\usepackage[squaren]{SIunits}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{diagbox}
\usepackage{pdfpages}
\usepackage{dsfont}
\usepackage{xcolor}
\usepackage{soul}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{algorithmic}

\usepackage{hyperref}
\usepackage{multimedia}
\usepackage{array}
\usepackage{multirow}
\usepackage{booktabs}
\usepackage{eso-pic}
\usepackage{monster2e}
\usepackage{tikz}
\usepackage{svg}
\usepackage{layout}
\usepackage{xcolor}
\usepackage{fancybox}
\usepackage{setspace}
\usepackage{bbding}
\usepackage{calc}
\usepackage{multicol}
\usepackage[absolute,showboxes,overlay]{textpos}
\usetikzlibrary{calc,fadings,mindmap,trees,arrows,calc,tikzmark,shapes}
\usepackage[flushleft]{threeparttable}


\TPshowboxesfalse
\textblockorigin{0mm}{0mm}
\newcommand{\mathcolorbox}[2]{\colorbox{#1}{$\displaystyle #2$}}

% Icons
\newcommand{\vcenteredinclude}[2]{\begingroup
\setbox0=\hbox{\includesvg[scale=#2]{#1}}%
\parbox{\wd0}{\box0}\endgroup}


% Change margins for slides
\newenvironment{changemargin}[2]{% 
	\begin{list}{}{% 
			\setlength{\topsep}{0pt}% 
			\setlength{\leftmargin}{#1}% 
			\setlength{\rightmargin}{#2}% 
			\setlength{\listparindent}{\parindent}% 
			\setlength{\itemindent}{\parindent}% 
			\setlength{\parsep}{\parskip}% 
		}% 
		\item[]}{\end{list}} 


% Input
\input{style}
\input{../mathdef}
\newtheorem{proposition}{Proposition}
\newtheorem{assumption}{Assumption}
\newtheorem{remark}{Remark}
\newtheorem{property}{Property}

% Style

\TPshowboxesfalse
\textblockorigin{0mm}{0mm}

\setbeamertemplate{footline}{% 
  \hfill% 
  \usebeamercolor[fg]{page number in head/foot}% 
  \usebeamerfont{page number in head/foot}% 
  \insertframenumber%
  %\,/\,\inserttotalframenumber
  \kern1em\vskip2pt% 
}
\beamertemplatenavigationsymbolsempty
\setbeamertemplate{navigation symbols}{}
%\setbeamertemplate{blocks}[rounded]
%\setbeamercolor{block title}{bg=bleu2,fg=white}%bg=background, fg= foreground
%\setbeamercolor{block body}{bg=lightgray}%bg=background, fg= foreground
\renewcommand{\sfdefault}{lmss}
\sffamily
\setbeamersize{text margin left=1cm,text margin right=1cm}


\author[shortname]{
Edouard Leurent \inst{1}, \inst{2} \and 
Odalric-Ambrym Maillard\inst{1}}
\institute[shortinst]{\inst{1} Inria SequeL.\and %
                      \inst{2} Renault Group.}

\title[]{Practical Open-Loop Optimistic Planning}
\date{}
\begin{document}
	
\setbeamertemplate{background canvas}[vertical shading][top=bleu2,middle=bleu2,bottom=bleu1]
\setbeamertemplate{footline}{\hspace{5em} \textcolor{white} {\null \hfill
		\scriptsize Würzburg, September 2019}\hspace{2em}\null \vspace*{3pt}}
	
\begin{frame}
\begin{textblock*}{40mm}[0,0](10mm,0mm)
	\includegraphics[width=3.4cm]{inria/logobleu2}
\end{textblock*}
\begin{textblock*}{40mm}[0,0](14mm,3mm)
	\includegraphics[width=2.6cm]{inria/renault_group}
\end{textblock*}

\begin{textblock*}{11.8cm}(4mm,40mm)
	\vspace{.3cm}
	\textcolor{white} {
		\Large \textbf{\hspace{0.5em}Practical Open-Loop Optimistic Planning}\\
		{\small %
			\vspace{1cm}
			\hspace{1.5em}\large\textbf{Edouard Leurent$^{1,2}$, Odalric-Ambrym Maillard$^1$}\\
			\hspace{2.5em}${}^1$ SequeL, Inria Lille -- Nord Europe\\
			\hspace{2.5em}${}^2$ Renault Group\\
	}}
\end{textblock*}

\begin{textblock*}{40mm}[0,0](10mm,76mm)
	\begin{picture}(5,80)
	\put(0,20){\includegraphics[width=3.8cm,height=1.5cm]{inria/logobasbleuV1}}
	\put(13,35){
		\footnotesize \textcolor{bleu2}{ECML PKDD 2019}
	}
	\end{picture}
\end{textblock*}

\vspace*{-4pt}
\end{frame}

\setbeamertemplate{background canvas}[vertical shading][top=blanc, middle=blanc,bottom=blanc]
\setbeamercolor{footlinecolor}{fg=blanc,bg=bleu2}
\setbeamertemplate{footline}
{
\begin{beamercolorbox}[wd=1\paperwidth,ht=15.5pt]{footlinecolor}
		\hspace{3mm}
		\includegraphics[width=14mm]{inria/logobastrans}
		\hspace{.4cm}
		\raisebox{3.2ex}
		{\scriptsize Practical Open-Loop Optimistic Planning}\hfill
		\raisebox{3.2ex}
		{Würzburg - \insertframenumber/\inserttotalframenumber \hspace{5mm}
			\null }
\end{beamercolorbox}
}

\begin{frame}{Motivation | Sequential Decision Making}
\begin{center}
    \includegraphics[trim=0 275 0 25,clip, width=0.75\linewidth]{img/diagram1.pdf}
\end{center}

\begin{block}{Markov Decision Processes}
\begin{enumerate}
    \item Observe state $s\in S$;
    \item Pick a \hlb{discrete} action $a\in A$;
    \item Transition to a next state $s'\sim \hler{\probability{s'|s,a}}$;
    \item Receive a \hlb{bounded} reward $r\in[0, 1]$ drawn from $\hler{\probability{r|s, a}}$.
\end{enumerate}
\begin{center}
    Objective: maximise \hlg{V = $\expectedvalue \left[\sum_{t=0}^\infty \gamma^t r_t \right]$}
\end{center}
\end{block}
\end{frame}


\begin{frame}{Motivation | Example}
\begin{block}{The \texttt{highway-env} environment \href{https://github.com/eleurent/highway-env}{\vcenteredinclude{img/github}{0.04}}}
\begin{center}
    \href{https://github.com/eleurent/highway-env}{\includegraphics[width=\linewidth]{img/highway-env}}
\end{center}
\end{block}
\end{frame}

\begin{frame}{Motivation | How to solve MDPs?}
\begin{exampleblock}{Online \emph{Planning}}
\begin{itemize}
    \item we have access to a \hlg{generative model}: 
    \begin{itemize}
        \item[\incarrow] yields samples of $s', r \sim \probability{s',r|s,a}$ when queried
    \end{itemize}
\end{itemize}
\begin{center}
    \includegraphics<1>[trim=0 25 0 50,clip, width=0.7\linewidth]{img/diagram2.pdf}
    \includegraphics<2>[trim=0 25 0 50,clip, width=0.7\linewidth]{img/diagram3.pdf}
    \includegraphics<3>[trim=0 25 0 50,clip, width=0.7\linewidth]{img/diagram4.pdf}
    \includegraphics<4>[trim=0 25 0 50,clip, width=0.7\linewidth]{img/diagram5.pdf}
    \includegraphics<5>[trim=0 25 0 50,clip, width=0.7\linewidth]{img/diagram6.pdf}
    \includegraphics<6>[trim=0 25 0 50,clip, width=0.7\linewidth]{img/diagram7.pdf}
\end{center}
\end{exampleblock}
\end{frame}

\begin{frame}{Motivation | How to solve MDPs?}
\begin{exampleblock}{Online \emph{Planning}}
\begin{itemize}
    \item we have access to a \hlg{generative model}: 
    \begin{itemize}
        \item[\incarrow] yields samples of $s', r \sim \probability{s',r|s,a}$ when queried
    \end{itemize}
    \item \hlr{fixed budget}: the model can only be queried $n$ times
\end{itemize}
\begin{center}
Objective: minimize $\expectedvalue \underbrace{\hler{V^* - V(n)}}_{\text{Simple Regret }r_n}$
\end{center}
\begin{flushright}
An \hlb{exploration-exploitation} problem.
\end{flushright}
\end{exampleblock}
\end{frame}


\begin{frame}{Optimistic Planning}
    % \begin{alertblock}{Previously: Combinatorial Search}
    % \begin{itemize}
    %     \item Branch pruning and heuristic utility functions
    % \end{itemize}
    % \end{alertblock}
    
    \begin{exampleblock}{Optimism in the Face of Uncertainty}
    Given a set of decisions $a\in A$ with uncertain outcomes $\nu_a$, pick the one with the \hlg{highest upper-confidence bound}.\pause
    
    \begin{itemize}
        \item Either you performed well;\pause
        \item or you learned something.\pause
    \end{itemize}
    \end{exampleblock}
    
    \begin{block}{Instances}
    \begin{itemize}
        \item Monte-carlo tree search (\texttt{MCTS}) [\cite{Coulom2006}]: \texttt{CrazyStone}
        \item Reframed in the bandit setting as \texttt{UCT} [\cite{Kocsis2006}], still very popular (e.g. \texttt{Alpha Go}).
        \item An asymptotic analysis but no finite time guarantee.
    \end{itemize}
    \end{block}
\end{frame}


\begin{frame}{Failing cases of \texttt{UCT}}
    It was analysed in [\cite{Coquelin2007}]
    \begin{center}
    \includegraphics[width=0.8\textwidth]{img/uct_fail}
    \end{center}
    The sample complexity of is lower-bounded by \hlr{$O(\exp(\exp(D)))$}.
\end{frame}

\begin{frame}{Failing cases of \texttt{UCT}}
    Not just a theoretical counter-example.
    \begin{center}
    \includegraphics[width=0.8\textwidth]{img/uct_trap}\\
    \bigskip
    \includesvg[width=0.5\textwidth]{img/uct_fail_hw}
    \end{center}
\end{frame}

\begin{frame}{Can we get better guarantees?}
    \begin{block}{\OPD: Optimistic Planning for Deterministic systems}
    \begin{itemize}
        \item Introduced by [\cite{Hren2008}]
        \item Another \hlg{optimistic} algorithm
        \item Only for \hlr{deterministic} MDPs
    \end{itemize}
    \end{block}
    \begin{theorem}[\OPD sample complexity]
    \begin{equation*}
    \expectedvalue r_n = 
      \cO\left(n^{-\frac{\log 1/\gamma}{\log \kappa}}\right), \text{if}\ \kappa > 1 
    \end{equation*}
    \end{theorem}
    \pause
\begin{block}{\OLOP: Open-Loop Optimistic Planning}
    \begin{itemize}
        \item Introduced by [\cite{Bubeck2010}]
        \item Extends \OPD to the \hlg{stochastic} setting
        \item Only considers \hlr{open-loop} policies, i.e. sequences of actions
    \end{itemize}
    \end{block}
\end{frame}

% \begin{frame}{A Benchmark of Planning Algorithms}
%     \small
%     \begin{threeparttable}
%     \centering
%     \begin{tabular}{cccc}
%     \toprule
%         Algorithm & Complexity & Does it run? & Does it work?\\
%         \midrule
%         \texttt{MCTS} & ? & \hlg{YES} & ?\\
%         \texttt{SparseSampling}\tnote{1} & $(1/\epsilon)^{\log 1/\epsilon}$ & \hlg{YES} & \hlr{NO} \\
%         \texttt{UCT} & $\exp(\exp(D))$ & \hlg{YES} & \hly{KIND OF} \\
%         \texttt{OPD}\tnote{2} & $n^{-\frac{\log1/\gamma}{\log \kappa}}$ & \hlg{YES} & \hlg{YES} \\
%         \OLOP & $n^{-\min(\frac{1}{2}, \frac{\log1/\gamma}{\log \kappa})}$ & \hly{KIND OF} & \hlr{NO} \\
%         \texttt{ST0P}\tnote{1} & $(1/\epsilon)^{2+\frac{\log \kappa'}{\log1/\gamma}+o(1)}$ & \hlr{NO} & ? (\hlr{NO})\\
%         \texttt{TrailBlazer}\tnote{1} & $(1/\epsilon)^{\frac{\log N\kappa}{\log1/\gamma}}(\log\frac{1}{\delta\epsilon})^\alpha$ & \hlg{YES} & \hlr{NO}\\
%         \texttt{PlatYPOOs}\tnote{2} & $\leq$ \OLOP & \hlg{YES} & \hlg{YES}\\
%         \bottomrule
%     \end{tabular}
    
%     \begin{tablenotes}
%     \item[1] In the PAC framework. 
%     \item[2] With deterministic dynamics
%     \end{tablenotes}
%     \end{threeparttable}
% \end{frame}

\begin{frame}{The idea behind \OLOP}
\begin{center}
\includesvg[width=0.8\textwidth]{img/olop-explain}
\end{center}
% \begin{center}
% \scalebox{0.7}{
% \begin{algorithm}[H]
% \DontPrintSemicolon
% \footnotesize
% \For{each episode $m = 1, \cdots, M$}{
% Compute $U_a(m-1)$ from \eqref{eq:Ua} for all $a\in\mathcal{T}$\;
% Compute $B_a(m-1)$ from \eqref{eq:Ba} for all $a\in A^L$\;\label{alg:b_values_compute}
% Sample a sequence with highest B-value: $a^m \in \argmax_{a\in A^L} B_a(m-1)$.\;
% }
% \Return the most played sequence $a(n) \in \argmax_{a\in A^L} T_a(M)$
% \caption{General structure for Open-Loop Optimistic Planning}
% \label{algo:kl-olop}
% \end{algorithm}}
% \end{center}
\end{frame}

\begin{frame}{The idea behind \OLOP}
\begin{center}
\includesvg[width=0.8\textwidth]{img/olop-explain-2}
\end{center}
% \begin{center}
% \scalebox{0.7}{
% \begin{algorithm}[H]
% \DontPrintSemicolon
% \footnotesize
% \For{each episode $m = 1, \cdots, M$}{
% Compute $U_a(m-1)$ from \eqref{eq:Ua} for all $a\in\mathcal{T}$\;
% Compute $B_a(m-1)$ from \eqref{eq:Ba} for all $a\in A^L$\;
% Sample a sequence with highest B-value: $a^m \in \argmax_{a\in A^L} B_a(m-1)$.\;
% }
% \Return the most played sequence $a(n) \in \argmax_{a\in A^L} T_a(M)$
% \caption{General structure for Open-Loop Optimistic Planning}
% \end{algorithm}}
% \end{center}
\end{frame}

\begin{frame}{Under the hood}
    \begin{block}{\OLOP main tool: the Chernoff-Hoeffding deviation inequality}
        \begin{equation*}
             \underbrace{U^{\mu}_a(m)}_{\text{Upper bound}} \eqdef \underbrace{\hat{\mu}_a(m)}_{\text{Empirical mean}} + \underbrace{\sqrt{\frac{2 \log M}{T_a(m)}}}_{\text{Confidence interval}}
        \end{equation*}
    \end{block}
    \pause
    
    \begin{block}{\OPD: upper-bound all the future rewards by 1}
    \begin{equation*}
    \label{eq:Ua}
        U_a(m) \eqdef \sum_{t=1}^h \underbrace{\gamma^t U^{\mu}_{a_{1:t}}(m)}_{\text{Past rewards}} + \underbrace{\frac{\gamma^{h+1}}{1-\gamma}}_{\text{Future rewards}}
    \end{equation*}
    \end{block}
    \pause
    
    \begin{block}{\emph{Bounds sharpening}}
    \begin{equation*}
    \label{eq:Ba}
        B_a(m) \eqdef \inf_{1 \leq t \leq L} U_{a_{1:t}}(m)
    \end{equation*}
    \end{block}
\end{frame}

\begin{frame}{Does it work?}
\begin{center}
    \includesvg[width=0.7\textwidth]{img/hw_return_olop_fail} \\
    Our objective: \hlb{understand} and \hlg{bridge} this gap.
\end{center}
\begin{flushright}
Make \OLOP \emph{practical}.
\end{flushright}
\end{frame}

\begin{frame}{What's wrong with \OLOP?}
    Overly optimistic, especially in the low-budget regime.

    \begin{alertblock}{Intuitive explanation}
    \begin{itemize}
        \item Unintended behaviour happens when $\hler{U^{\mu}_a(m) > 1}, \forall a$.
        \begin{equation*}
             U^{\mu}_a(m) = \underbrace{\hat{\mu}_a(m)}_{\in [0,1]} + \underbrace{\sqrt{\frac{2 \log M}{T_a(m)}}}_{> 0}
        \end{equation*}
        \pause
        \item Then the sequence $(U_{a_{1:t}}(m))_t$ is non-decreasing
        \begin{equation*}
        U_a(m) = \sum_{t=1}^h \gamma^t U^{\mu}_{a_{1:t}}(m) + \frac{\gamma^{h+1}}{1-\gamma}
        \end{equation*}
        \pause
        \item Then \hlr{$B_a(m) = U_{a_{1:1}}(m)$}
        \begin{equation*}
        B_a(m) = \inf_{1 \leq t \leq L} U_{a_{1:t}}(m)
        \end{equation*}
    \end{itemize}
    \end{alertblock}
    
\end{frame}

\begin{frame}{What's wrong with \OLOP?}
\begin{block}{What we were promised}
\begin{center}
\includesvg[width=0.8\textwidth]{img/olop-explain-2}
\end{center}
\end{block}
\end{frame}

\begin{frame}{What's wrong with \OLOP?}
\begin{alertblock}{What we actually get}
\begin{center}
\includesvg[width=0.8\textwidth]{img/olop-explain-3}
\end{center}
\end{alertblock}
\begin{flushright}
\OLOP behaves as \hlr{uniform planning}!
\end{flushright}
\end{frame}

\begin{frame}{What's wrong with \OLOP?}
    \begin{block}{How long does it last?}
    \begin{itemize}
        \item Recall: unintended behaviour happens when $\hler{U^{\mu}_a(m) > 1}, \forall a$.
    \begin{equation*}
         U^{\mu}_a(m) = \underbrace{\hat{\mu}_a(m)}_{\in [0,1]} + \underbrace{\sqrt{\frac{2 \log M}{T_a(m)}}}_{> 0}
    \end{equation*}
    \pause
    \item[\incarrow] $U^{\mu}_a(m)$ decreases as $\cO\left(1/\sqrt{T_a(m)}\right)$
    \pause
    \item[\incarrow] The issue lasts longer where $\underbrace{\hat{\mu}_a(m) \simeq 1}_{\text{near-optimal regions}}$
    \end{itemize}
    \end{block}
\end{frame}

\begin{frame}{Our contribution: Kullback-Leibler \OLOP}
    We summon the upper-confidence bound from \texttt{kl-UCB} [\cite{Cappe2013}]:
    \begin{equation*}
        U^{\mu}_a(m) \eqdef \max \left\{q\in I: T_a(m) d(\hat{\mu}_a(m), q) \leq f(m) \right\}
    \end{equation*}
    \pause
    \begin{center}
    \begin{tabular}{ccc}
    \toprule
        Algorithm & \OLOP & \KLOLOP \\
        \midrule
        Interval $I$ & $\mathbb{R}$ & [0, 1] \\
        Divergence $d$ & $d_{\texttt{QUAD}}$ & $d_{\texttt{BER}}$ \\
        $f(m)$ & $4 \log M$ & $2\log M + 2 \log\log M$\\
        \bottomrule
    \end{tabular}
    \end{center}
    
    \begin{align*}
    d_{\texttt{QUAD}}(p,q) &\eqdef 2(p-q)^2\\
    d_{\texttt{BER}}(p, q) &\eqdef p \log \frac{p}{q} + (1-p)\log\frac{1-p}{1-q}
    \end{align*}
\end{frame}

\begin{frame}{Our contribution: Kullback-Leibler \OLOP}
\begin{center}
\vspace{-2em}
    \includegraphics[width=0.6\textwidth]{../img/ukl}
\end{center}
\vspace{-1em}
\pause
And now,
\begin{itemize}
    \item \hlg{$U^{\mu}_a(m) \in I = [0, 1], \forall a$}. \pause 
    \item The sequence $(U_{a_{1:t}}(m))_t$ is \hlg{non-increasing} \pause
    \item $B_a(m) = U_a(m)$, the \emph{bound sharpening} step is \hlb{superfluous}.
\end{itemize}
\end{frame}

\begin{frame}{Sample complexity}

\begin{theorem}[Sample complexity]
\label{thm:regret}
\KLOLOP enjoys the same regret bounds as \OLOP. More precisely, \KLOLOP satisfies:
\begin{equation*}
    \expectedvalue r_n = \begin{cases}
      \tilde{\cO}\left(n^{-\frac{\log 1/\gamma}{\log \kappa'}}\right), & \text{if}\ \gamma\sqrt{\kappa'} > 1 \\
      \tilde{\cO}\left(n^{-\frac{1}{2}}\right), & \text{if}\ \gamma\sqrt{\kappa'} \leq 1
    \end{cases}
\end{equation*}
\end{theorem}
\end{frame}

\begin{frame}{Time complexity}
\begin{block}{Original \KLOLOP}
\emph{Compute $B_a(m-1)$ from \eqref{eq:Ba} \hlr{for all $a\in A^L$}}
\end{block}
\begin{block}{Lazy \KLOLOP}
\centering
\includesvg[width=0.6\textwidth]{../img/tree.svg}
\end{block}

\begin{property}[Time and memory complexity]
\begin{equation*}
    \frac{C(\texttt{Lazy KL-OLOP})}{C(\KLOLOP)} = \frac{\hleg{nK}}{\hler{K^{L}}}
\end{equation*}
\end{property}
\end{frame}

\begin{frame}{Experiments | Expanded Trees}
    \includesvg[width=\textwidth]{../img/tree_OPD}
\end{frame}

\begin{frame}{Experiments | Expanded Trees}
    \includesvg[width=\textwidth]{../img/tree_OLOP}
\end{frame}

\begin{frame}{Experiments | Expanded Trees}
    \includesvg[width=\textwidth]{../img/tree_KL-OLOP}
\end{frame}

\begin{frame}{Experiments | Highway}
    \includesvg[width=\textwidth]{../img/hw_return}
\end{frame}
\begin{frame}{Experiments | Gridworld}
    \includesvg[width=\textwidth]{../img/gw_return}
\end{frame}
\begin{frame}{Experiments | Stochastic Gridworld}
    \includesvg[width=\textwidth]{../img/gw_stoch_return}
\end{frame}

\begin{frame}
        \frametitle{References}
        \printbibliography
\end{frame}

\end{document}

